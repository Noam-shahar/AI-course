{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNe2t2+7DZeyKvjmKUSa2FW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noam-shahar/AI-course/blob/main/HW5_Drone_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Link to prompts: https://chat.openai.com/share/5478d433-fc4a-4efc-8b95-33d9a1563ac0"
      ],
      "metadata": {
        "id": "9iqJTZrJQU0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean slate:"
      ],
      "metadata": {
        "id": "8j3LFD9eP1XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/sample_data'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory):\n",
        "    # Remove all files in the directory\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        try:\n",
        "            if os.path.isfile(file_path):\n",
        "                os.remove(file_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error deleting {file_path}: {e}\")\n",
        "else:\n",
        "    print(f\"Directory '{directory}' does not exist.\")"
      ],
      "metadata": {
        "id": "GGEX25lNPxsx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organizing:"
      ],
      "metadata": {
        "id": "hgJuVzmvP4HL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irxGQCRyl2vT",
        "outputId": "a9f51855-79b2-4d0f-89a4-ec564f169707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Directory 'drone_data' deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Define the path to the new \"Road2_drone_data\" directory\n",
        "copied_folder_path = '/content/sample_data/Road2_drone_data'\n",
        "\n",
        "# Create the \"Road2_drone_data\" directory\n",
        "os.makedirs(copied_folder_path)\n",
        "\n",
        "# Create paths for the new folders within \"Road2_drone_data\"\n",
        "true_drones_path = os.path.join(copied_folder_path, 'True_drones')\n",
        "fake_ones_path = os.path.join(copied_folder_path, 'Fake_ones')\n",
        "og_path = os.path.join(copied_folder_path, 'OG')\n",
        "\n",
        "# Create the new folders\n",
        "os.makedirs(true_drones_path)\n",
        "os.makedirs(fake_ones_path)\n",
        "os.makedirs(og_path)\n",
        "\n",
        "# Define source and destination paths for the copy operation\n",
        "source_path = '/content/drive/MyDrive/drone_data'\n",
        "destination_path = os.path.join(og_path, os.path.basename(source_path))  # Destination path within OG\n",
        "\n",
        "# Perform the copy operation\n",
        "shutil.copytree(source_path, destination_path)\n",
        "\n",
        "# Define the path to the \"Testing\" directory within \"Road2_drone_data\"\n",
        "testing_folder_path = '/content/sample_data/Road2_drone_data/Testing'\n",
        "\n",
        "# Create the \"Testing\" directory if it doesn't exist\n",
        "os.makedirs(testing_folder_path, exist_ok=True)\n",
        "\n",
        "# Create \"True_drones\" and \"Fake_ones\" folders within \"Testing\"\n",
        "true_drones_testing_path = os.path.join(testing_folder_path, 'True_drones')\n",
        "fake_ones_testing_path = os.path.join(testing_folder_path, 'Fake_ones')\n",
        "\n",
        "# Create the new folders within \"Testing\"\n",
        "os.makedirs(true_drones_testing_path, exist_ok=True)\n",
        "os.makedirs(fake_ones_testing_path, exist_ok=True)\n",
        "\n",
        "# Define paths\n",
        "og_folder_path = '/content/sample_data/Road2_drone_data/OG'\n",
        "drone_data_folder_path = '/content/sample_data/Road2_drone_data/OG/drone_data'\n",
        "\n",
        "# Get the list of files in the drone_data folder\n",
        "drone_data_files = os.listdir(drone_data_folder_path)\n",
        "\n",
        "# Move files from drone_data folder to OG folder\n",
        "for file_name in drone_data_files:\n",
        "    source_file_path = os.path.join(drone_data_folder_path, file_name)\n",
        "    destination_file_path = os.path.join(og_folder_path, file_name)\n",
        "    shutil.move(source_file_path, destination_file_path)\n",
        "\n",
        "# Define the path to the drone_data folder\n",
        "drone_data_folder_path = '/content/sample_data/Road2_drone_data/OG/drone_data'\n",
        "\n",
        "# Check if the directory is empty\n",
        "if not os.listdir(drone_data_folder_path):\n",
        "    # Directory is empty, delete it\n",
        "    os.rmdir(drone_data_folder_path)\n",
        "    print(\"Directory 'drone_data' deleted successfully.\")\n",
        "else:\n",
        "    print(\"Directory 'drone_data' is not empty. Not deleted.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process 1 - Fake drones (Testing):"
      ],
      "metadata": {
        "id": "PtQLEZ9iLL1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Function to perform process 1: Randomly crop images to 28x28 and save in \"Fake_ones\" folder\n",
        "def process_1(image_path, save_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale (black and white)\n",
        "\n",
        "    if img is not None:  # Ensure image was read successfully\n",
        "        # Get random coordinates for cropping\n",
        "        h, w = img.shape[:2]\n",
        "        start_h = random.randint(0, max(0, h - 28))\n",
        "        start_w = random.randint(0, max(0, w - 28))\n",
        "\n",
        "        # Crop the image to 28x28\n",
        "        cropped_img = img[start_h:start_h+28, start_w:start_w+28]\n",
        "\n",
        "        # Save the cropped image\n",
        "        cv2.imwrite(save_path, cropped_img)\n",
        "\n",
        "        # Save corresponding text file\n",
        "        text_file_name = os.path.splitext(os.path.basename(save_path))[0] + '.txt'\n",
        "        text_file_path = os.path.join(os.path.dirname(save_path), text_file_name)\n",
        "        with open(text_file_path, 'w') as file:\n",
        "            file.write(\"not a drone\")\n",
        "    else:\n",
        "        print(f\"Skipping {image_path} as it's not a valid image.\")\n",
        "\n",
        "# Define paths\n",
        "og_folder_path = '/content/sample_data/Road2_drone_data/OG'\n",
        "fake_ones_testing_path = '/content/sample_data/Road2_drone_data/Testing/Fake_ones'\n",
        "\n",
        "# List image files in the OG folder\n",
        "og_image_files = [file for file in os.listdir(og_folder_path) if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "# Process 5 random images from OG folder\n",
        "if len(og_image_files) > 0:\n",
        "    for i in range(min(5, len(og_image_files))):\n",
        "        random_image_name = random.choice(og_image_files)\n",
        "        random_image_path = os.path.join(og_folder_path, random_image_name)\n",
        "\n",
        "        # Create corresponding paths for processed image and text file in Fake_ones\n",
        "        processed_image_path = os.path.join(fake_ones_testing_path, random_image_name)\n",
        "\n",
        "        # Perform Process 1: Random crop and save in \"Fake_ones\" folder\n",
        "        process_1(random_image_path, processed_image_path)\n",
        "else:\n",
        "    print(\"No image files found in the 'OG' folder.\")\n"
      ],
      "metadata": {
        "id": "o1IQrHh4rOM5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process 2 - Real drones (Testing):"
      ],
      "metadata": {
        "id": "q6y6JS7kLSNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os                   # Operating System module for directory operations\n",
        "import cv2                  # OpenCV for image processing\n",
        "import random               # For random selection of images\n",
        "from keras.preprocessing import image  # Keras for image preprocessing\n",
        "\n",
        "# Function to extract bounding box coordinates from YOLOv8 format\n",
        "def extract_bbox_from_yolov8(label_path, img_width, img_height):\n",
        "    try:\n",
        "        # Read lines from the label file\n",
        "        with open(label_path, 'r') as file:\n",
        "            data = file.readlines()\n",
        "\n",
        "        # Check if label file has content\n",
        "        if len(data) > 0:\n",
        "            # Split the content by spaces and convert values to float\n",
        "            bbox_values = list(map(float, data[0].split()))\n",
        "\n",
        "            # Check if the number of values is sufficient for a bounding box\n",
        "            if len(bbox_values) >= 4:\n",
        "                # Extract the first 4 values as x_center, y_center, width, height\n",
        "                x_center, y_center, width, height = bbox_values[1:]\n",
        "\n",
        "                # Calculate bounding box coordinates (x, y, w, h)\n",
        "                w, h = width * img_width, height * img_height  # Normalize to image dimensions\n",
        "                x = (x_center * img_width) - (w / 2)\n",
        "                y = (y_center * img_height) - (h / 2)\n",
        "\n",
        "                return int(x), int(y), int(w), int(h)\n",
        "            else:\n",
        "                # Handle cases where insufficient values are found in label file\n",
        "                print(f\"Invalid format in label file '{label_path}': Expected at least 4 values for bbox, found {len(bbox_values)}\")\n",
        "                return None\n",
        "        else:\n",
        "            # Handle empty label files\n",
        "            print(f\"Empty label file '{label_path}'\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # Handle any exceptions during parsing\n",
        "        print(f\"Error parsing label file '{label_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to process images according to Process 2\n",
        "def process_2(image_path, label_path, save_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale (black and white)\n",
        "\n",
        "    if img is not None and img.size > 0:\n",
        "        img_height, img_width = img.shape  # Updated line to get height and width (no channels for grayscale)\n",
        "\n",
        "        bbox = extract_bbox_from_yolov8(label_path, img_width, img_height)\n",
        "\n",
        "        if bbox is not None:\n",
        "            x, y, w, h = bbox\n",
        "            cropped_img = img[max(0, y):min(img_height, y + h), max(0, x):min(img_width, x + w)]\n",
        "\n",
        "            # Check if the cropped image is valid and has the correct shape\n",
        "            if cropped_img.size > 0:\n",
        "                resized_img = cv2.resize(cropped_img, (28, 28))\n",
        "\n",
        "                # Save the processed image\n",
        "                cv2.imwrite(save_path, resized_img)\n",
        "\n",
        "                # Create a text file (with the same name as the image) and write \"drone\" to it\n",
        "                text_file_name = os.path.splitext(os.path.basename(save_path))[0] + '.txt'\n",
        "                text_file_path = os.path.join(os.path.dirname(save_path), text_file_name)\n",
        "                with open(text_file_path, 'w') as file:\n",
        "                    file.write(\"drone\")\n",
        "            else:\n",
        "                print(f\"Skipping {image_path} due to invalid crop or shape.\")\n",
        "        else:\n",
        "            print(f\"Skipping {image_path} due to label parsing error.\")\n",
        "    else:\n",
        "        print(f\"Skipping {image_path} as it's not a valid image.\")\n",
        "\n",
        "# Define paths for the original images and the destination for processed images\n",
        "og_folder_path = '/content/sample_data/Road2_drone_data/OG'\n",
        "true_drones_testing_path = '/content/sample_data/Road2_drone_data/Testing/True_drones'\n",
        "\n",
        "# Get a list of image files in the original folder\n",
        "og_image_files = [file for file in os.listdir(og_folder_path) if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "# Process a maximum of 5 random images from the original folder\n",
        "if len(og_image_files) > 0:\n",
        "    for i in range(min(5, len(og_image_files))):\n",
        "        random_image_name = random.choice(og_image_files)\n",
        "        random_image_path = os.path.join(og_folder_path, random_image_name)\n",
        "\n",
        "        label_file_name = os.path.splitext(random_image_name)[0] + '.txt'\n",
        "        label_file_path = os.path.join(og_folder_path, label_file_name)\n",
        "\n",
        "        processed_image_path = os.path.join(true_drones_testing_path, random_image_name)\n",
        "\n",
        "        # Process the image according to Process 2\n",
        "        process_2(random_image_path, label_file_path, processed_image_path)\n",
        "else:\n",
        "    print(\"No image files found in the 'OG' folder.\")\n"
      ],
      "metadata": {
        "id": "Ii23AJFyuRtj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process 1 - Fake drones:"
      ],
      "metadata": {
        "id": "_wO5ojM6LT2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Function to perform process 1: Randomly crop images to 28x28 and save in \"Fake_ones\" folder\n",
        "def process_1(image_path, save_path):\n",
        "    # Read the image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale (black and white)\n",
        "\n",
        "    if img is not None:  # Ensure image was read successfully\n",
        "        # Get random coordinates for cropping\n",
        "        h, w = img.shape[:2]\n",
        "        start_h = random.randint(0, max(0, h - 28))\n",
        "        start_w = random.randint(0, max(0, w - 28))\n",
        "\n",
        "        # Crop the image to 28x28\n",
        "        cropped_img = img[start_h:start_h+28, start_w:start_w+28]\n",
        "\n",
        "        # Save the cropped image\n",
        "        cv2.imwrite(save_path, cropped_img)\n",
        "\n",
        "        # Save corresponding text file\n",
        "        text_file_name = os.path.splitext(os.path.basename(save_path))[0] + '.txt'\n",
        "        text_file_path = os.path.join(os.path.dirname(save_path), text_file_name)\n",
        "        with open(text_file_path, 'w') as file:\n",
        "            file.write(\"not a drone\")\n",
        "    else:\n",
        "        print(f\"Skipping {image_path} as it's not a valid image.\")\n",
        "\n",
        "# Define paths\n",
        "og_folder_path = '/content/sample_data/Road2_drone_data/OG'\n",
        "fake_ones_path = '/content/sample_data/Road2_drone_data/Fake_ones'\n",
        "\n",
        "# List image files in the OG folder\n",
        "og_image_files = [file for file in os.listdir(og_folder_path) if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "# Process all images from OG folder using Process 1 (random cropping)\n",
        "if len(og_image_files) > 0:\n",
        "     for i in range(len(og_image_files)):\n",
        "        random_image_name = og_image_files[i]  # Select images sequentially\n",
        "        random_image_path = os.path.join(og_folder_path, random_image_name)\n",
        "\n",
        "        # Create corresponding paths for processed image and text file in Fake_ones\n",
        "        processed_image_path = os.path.join(fake_ones_path, random_image_name)\n",
        "\n",
        "        # Perform Process 1: Random crop and save in \"Fake_ones\" folder\n",
        "        process_1(random_image_path, processed_image_path)\n",
        "else:\n",
        "    print(\"No image files found in the 'OG' folder.\")\n"
      ],
      "metadata": {
        "id": "vCW0pKz0JA1l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process 2 - Real drones:"
      ],
      "metadata": {
        "id": "1J-U1shPLVsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os                   # Operating System module for directory operations\n",
        "import cv2                  # OpenCV for image processing\n",
        "import random               # For random selection of images\n",
        "from keras.preprocessing import image  # Keras for image preprocessing\n",
        "\n",
        "# Function to extract bounding box coordinates from YOLOv8 format\n",
        "def extract_bbox_from_yolov8(label_path, img_width, img_height):\n",
        "    try:\n",
        "        # Read lines from the label file\n",
        "        with open(label_path, 'r') as file:\n",
        "            data = file.readlines()\n",
        "\n",
        "        # Check if label file has content\n",
        "        if len(data) > 0:\n",
        "            # Split the content by spaces and convert values to float\n",
        "            bbox_values = list(map(float, data[0].split()))\n",
        "\n",
        "            # Check if the number of values is sufficient for a bounding box\n",
        "            if len(bbox_values) >= 4:\n",
        "                # Extract the first 4 values as x_center, y_center, width, height\n",
        "                x_center, y_center, width, height = bbox_values[1:]\n",
        "\n",
        "                # Calculate bounding box coordinates (x, y, w, h)\n",
        "                w, h = width * img_width, height * img_height  # Normalize to image dimensions\n",
        "                x = (x_center * img_width) - (w / 2)\n",
        "                y = (y_center * img_height) - (h / 2)\n",
        "\n",
        "                return int(x), int(y), int(w), int(h)\n",
        "            else:\n",
        "                # Handle cases where insufficient values are found in label file\n",
        "                print(f\"Invalid format in label file '{label_path}': Expected at least 4 values for bbox, found {len(bbox_values)}\")\n",
        "                return None\n",
        "        else:\n",
        "            # Handle empty label files\n",
        "            print(f\"Empty label file '{label_path}'\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        # Handle any exceptions during parsing\n",
        "        print(f\"Error parsing label file '{label_path}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to process images according to Process 2\n",
        "def process_2(image_path, label_path, save_path):\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale (black and white)\n",
        "\n",
        "    if img is not None and img.size > 0:\n",
        "        img_height, img_width = img.shape  # Updated line to get height and width (no channels for grayscale)\n",
        "\n",
        "        bbox = extract_bbox_from_yolov8(label_path, img_width, img_height)\n",
        "\n",
        "        if bbox is not None:\n",
        "            x, y, w, h = bbox\n",
        "            cropped_img = img[max(0, y):min(img_height, y + h), max(0, x):min(img_width, x + w)]\n",
        "\n",
        "            # Check if the cropped image is valid and has the correct shape\n",
        "            if cropped_img.size > 0:\n",
        "                resized_img = cv2.resize(cropped_img, (28, 28))\n",
        "\n",
        "                # Save the processed image\n",
        "                cv2.imwrite(save_path, resized_img)\n",
        "\n",
        "                # Create a text file (with the same name as the image) and write \"drone\" to it\n",
        "                text_file_name = os.path.splitext(os.path.basename(save_path))[0] + '.txt'\n",
        "                text_file_path = os.path.join(os.path.dirname(save_path), text_file_name)\n",
        "                with open(text_file_path, 'w') as file:\n",
        "                    file.write(\"drone\")\n",
        "            else:\n",
        "                print(f\"Skipping {image_path} due to invalid crop or shape.\")\n",
        "        else:\n",
        "            print(f\"Skipping {image_path} due to label parsing error.\")\n",
        "    else:\n",
        "        print(f\"Skipping {image_path} as it's not a valid image.\")\n",
        "\n",
        "# Define paths for the original images and the destination for processed images\n",
        "og_folder_path = '/content/sample_data/Road2_drone_data/OG'\n",
        "true_drones_path = '/content/sample_data/Road2_drone_data/True_drones'\n",
        "\n",
        "# Get a list of image files in the original folder\n",
        "og_image_files = [file for file in os.listdir(og_folder_path) if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "\n",
        "# Process all images from OG folder using Process 2\n",
        "if len(og_image_files) > 0:\n",
        "    for image_name in og_image_files:\n",
        "        image_path = os.path.join(og_folder_path, image_name)\n",
        "\n",
        "        label_file_name = os.path.splitext(image_name)[0] + '.txt'\n",
        "        label_file_path = os.path.join(og_folder_path, label_file_name)\n",
        "\n",
        "        processed_image_path = os.path.join(true_drones_path, image_name)\n",
        "\n",
        "        # Process the image according to Process 2\n",
        "        process_2(image_path, label_file_path, processed_image_path)\n",
        "else:\n",
        "    print(\"No image files found in the 'OG' folder.\")\n"
      ],
      "metadata": {
        "id": "EOdJe-sZJval"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting to TensorFlow datasets"
      ],
      "metadata": {
        "id": "JSDhGqPTcxEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Assuming labels are strings ('not a drone', 'drone') in the label files\n",
        "label_to_index = {'not a drone': 0, 'drone': 1}\n",
        "\n",
        "# Function to load images and labels from directories with categorical encoding\n",
        "def load_images_and_labels(directory):\n",
        "    image_data = []\n",
        "    label_data = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg'):\n",
        "            image_path = os.path.join(directory, filename)\n",
        "\n",
        "            # Load and preprocess image\n",
        "            image = tf.io.read_file(image_path)\n",
        "            image = tf.image.decode_jpeg(image)\n",
        "\n",
        "            # Append image and encoded label to lists\n",
        "            image_data.append(image)\n",
        "            if 'Fake' in directory:\n",
        "              label_data.append(0)\n",
        "            else:\n",
        "              label_data.append(1)\n",
        "\n",
        "    return image_data, label_data\n",
        "\n",
        "# Define paths for Fake_ones and True_drones\n",
        "fake_ones_path = '/content/sample_data/Road2_drone_data/Fake_ones'\n",
        "true_drones_path = '/content/sample_data/Road2_drone_data/True_drones'\n",
        "\n",
        "# Load images and labels for Fake_ones and True_drones\n",
        "fake_ones_images, fake_ones_labels = load_images_and_labels(fake_ones_path)\n",
        "true_drones_images, true_drones_labels = load_images_and_labels(true_drones_path)\n",
        "\n",
        "# Convert lists to TensorFlow datasets\n",
        "fake_ones_dataset = tf.data.Dataset.from_tensor_slices((fake_ones_images, fake_ones_labels))\n",
        "true_drones_dataset = tf.data.Dataset.from_tensor_slices((true_drones_images, true_drones_labels))\n",
        "\n",
        "# # Shuffle and batch the datasets (adjust batch sizes as needed)\n",
        "batch_size = 32  # Adjust batch size as per requirement\n",
        "fake_ones_dataset = fake_ones_dataset.shuffle(len(fake_ones_images)).batch(batch_size)\n",
        "true_drones_dataset = true_drones_dataset.shuffle(len(true_drones_images)).batch(batch_size)\n",
        "\n",
        "# Optionally, perform other transformations like normalization, resizing, etc.\n",
        "# Example:\n",
        "# fake_ones_dataset = fake_ones_dataset.map(normalize_images)\n",
        "# true_drones_dataset = true_drones_dataset.map(normalize_images)\n",
        "\n",
        "# Print the dataset shapes and types\n",
        "print(\"Fake ones dataset:\", fake_ones_dataset.element_spec)\n",
        "print(\"True drones dataset:\", true_drones_dataset.element_spec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc7YQuwKc2Gq",
        "outputId": "d21e4c41-4774-4f05-9c3f-6a2270106a07"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fake ones dataset: (TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n",
            "True drones dataset: (TensorSpec(shape=(None, 28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(fake_ones_images).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyxuedTRIzzQ",
        "outputId": "8d54bf51-cdf7-4350-d7fa-82128abebe2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4070, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging"
      ],
      "metadata": {
        "id": "ZvjH3CxPd3In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Combine fake ones and true drones datasets into a single dataset\n",
        "combined_dataset = tf.data.Dataset.concatenate(fake_ones_dataset, true_drones_dataset)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "combined_dataset_shuffled = combined_dataset.shuffle(buffer_size=len(combined_dataset), reshuffle_each_iteration=False)\n",
        "\n",
        "# Calculate the sizes for train and test sets\n",
        "total_size = len(combined_dataset)\n",
        "train_size = int(0.8 * total_size)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_dataset = combined_dataset_shuffled.take(train_size)\n",
        "test_dataset = combined_dataset_shuffled.skip(train_size)\n",
        "\n",
        "# Print the sizes of train and test sets\n",
        "print(\"Train dataset size:\", sum(1 for _ in train_dataset))\n",
        "print(\"Test dataset size:\", sum(1 for _ in test_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a_Qg824fYcz",
        "outputId": "c2cca334-b114-4a7e-bf28-af93e095c3cb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 204\n",
            "Test dataset size: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "wvMFTg-UeP1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# # Normalize pixel values between 0 and 1\n",
        "# train_images = train_images / 255.0\n",
        "# test_images = test_images / 255.0\n",
        "\n",
        "# Define and compile the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_dataset, validation_data = test_dataset, epochs=30)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRjSLmS33yCS",
        "outputId": "fd4d4e66-02fd-43a1-d5b5-8447269d4eea"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "204/204 [==============================] - 2s 6ms/step - loss: 50.2875 - accuracy: 0.6904 - val_loss: 9.5840 - val_accuracy: 0.8348\n",
            "Epoch 2/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 28.6954 - accuracy: 0.7451 - val_loss: 39.3567 - val_accuracy: 0.4791\n",
            "Epoch 3/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 27.7845 - accuracy: 0.7617 - val_loss: 8.3545 - val_accuracy: 0.8993\n",
            "Epoch 4/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 22.3790 - accuracy: 0.7591 - val_loss: 7.3899 - val_accuracy: 0.8956\n",
            "Epoch 5/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 14.3326 - accuracy: 0.8099 - val_loss: 6.2030 - val_accuracy: 0.9085\n",
            "Epoch 6/20\n",
            "204/204 [==============================] - 2s 8ms/step - loss: 18.7743 - accuracy: 0.7740 - val_loss: 12.1227 - val_accuracy: 0.4994\n",
            "Epoch 7/20\n",
            "204/204 [==============================] - 2s 11ms/step - loss: 15.7033 - accuracy: 0.7801 - val_loss: 5.7173 - val_accuracy: 0.8999\n",
            "Epoch 8/20\n",
            "204/204 [==============================] - 2s 11ms/step - loss: 11.0616 - accuracy: 0.8100 - val_loss: 7.2943 - val_accuracy: 0.8931\n",
            "Epoch 9/20\n",
            "204/204 [==============================] - 2s 11ms/step - loss: 12.6591 - accuracy: 0.7770 - val_loss: 23.7077 - val_accuracy: 0.4871\n",
            "Epoch 10/20\n",
            "204/204 [==============================] - 1s 7ms/step - loss: 11.2044 - accuracy: 0.7950 - val_loss: 16.7302 - val_accuracy: 0.8041\n",
            "Epoch 11/20\n",
            "204/204 [==============================] - 1s 7ms/step - loss: 7.4934 - accuracy: 0.8104 - val_loss: 15.5076 - val_accuracy: 0.7770\n",
            "Epoch 12/20\n",
            "204/204 [==============================] - 2s 8ms/step - loss: 9.9723 - accuracy: 0.7850 - val_loss: 10.3902 - val_accuracy: 0.8243\n",
            "Epoch 13/20\n",
            "204/204 [==============================] - 2s 8ms/step - loss: 5.5542 - accuracy: 0.8243 - val_loss: 7.8415 - val_accuracy: 0.8348\n",
            "Epoch 14/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 5.9327 - accuracy: 0.7985 - val_loss: 4.6110 - val_accuracy: 0.8618\n",
            "Epoch 15/20\n",
            "204/204 [==============================] - 2s 11ms/step - loss: 3.3545 - accuracy: 0.8194 - val_loss: 1.9404 - val_accuracy: 0.9128\n",
            "Epoch 16/20\n",
            "204/204 [==============================] - 3s 12ms/step - loss: 2.4386 - accuracy: 0.8428 - val_loss: 1.5402 - val_accuracy: 0.9103\n",
            "Epoch 17/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 1.9032 - accuracy: 0.8408 - val_loss: 1.3311 - val_accuracy: 0.8569\n",
            "Epoch 18/20\n",
            "204/204 [==============================] - 2s 10ms/step - loss: 1.7069 - accuracy: 0.8374 - val_loss: 3.2310 - val_accuracy: 0.8157\n",
            "Epoch 19/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 1.1812 - accuracy: 0.8659 - val_loss: 0.8461 - val_accuracy: 0.9128\n",
            "Epoch 20/20\n",
            "204/204 [==============================] - 1s 6ms/step - loss: 1.3898 - accuracy: 0.8010 - val_loss: 0.9422 - val_accuracy: 0.8827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way to split data: (we'll need a different way to normalize though)"
      ],
      "metadata": {
        "id": "ZSd5bFlGO7yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/sample_data/Road2_drone_data'\n",
        "split_p = 0.2\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=split_p,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(28, 28),\n",
        "  batch_size=32)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=split_p,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(28, 28),\n",
        "  batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfLl6Ss7LgH9",
        "outputId": "b6f9833b-bf96-4779-df85-a79fb29179b6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8140 files belonging to 2 classes.\n",
            "Using 6512 files for training.\n",
            "Found 8140 files belonging to 2 classes.\n",
            "Using 1628 files for validation.\n"
          ]
        }
      ]
    }
  ]
}